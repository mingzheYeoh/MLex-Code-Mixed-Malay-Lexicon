"""
MLEX - äº¤äº’å¼è¯ä¹‰æ¶ˆæ­§å·¥å…·
Interactive Word Sense Disambiguation Tool
"""

import os
import json
from typing import List, Dict, Optional, Tuple
import google.generativeai as genai
from dataclasses import dataclass
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class WordSense:
    """è¯ä¹‰æ•°æ®ç»“æ„"""
    sense_id: str
    definition: str
    examples: tuple = None
    confidence: float = 0.0


class GeminiWSDService:
    """ä½¿ç”¨Google Geminiè¿›è¡ŒWord Sense Disambiguation"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        
        if not self.api_key:
            raise ValueError(
                "éœ€è¦Gemini APIå¯†é’¥ï¼\n"
                "è¯·è®¾ç½®: export GEMINI_API_KEY='your-key'"
            )
        
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')
        
        self.generation_config = {
            'temperature': 0.2,
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 1024,
        }
        
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
    
    def disambiguate(
        self, 
        word: str, 
        context: str, 
        candidate_senses: tuple
    ) -> List[Dict]:
        """è¯ä¹‰æ¶ˆæ­§"""
        
        prompt = self._build_simple_prompt(word, context, candidate_senses)
        
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            if not response or not response.candidates:
                return self._get_fallback_result(candidate_senses)
            
            candidate = response.candidates[0]
            if candidate.finish_reason != 1:
                return self._get_fallback_result(candidate_senses)
            
            try:
                response_text = response.text
            except (ValueError, AttributeError):
                return self._get_fallback_result(candidate_senses)
            
            result = self._parse_response(response_text, candidate_senses)
            return result if result else self._get_fallback_result(candidate_senses)
            
        except Exception as e:
            logger.error(f"APIé”™è¯¯: {e}")
            return self._get_fallback_result(candidate_senses)
    
    def _build_simple_prompt(self, word: str, context: str, senses: tuple) -> str:
        """æ„å»ºprompt"""
        sense_list = []
        for sense in senses:
            sense_list.append(f'{{"{sense.sense_id}": "{sense.definition}"}}')
        
        senses_json = ",\n".join(sense_list)
        
        prompt = f"""Word: {word}
Context: {context}

Senses: [{senses_json}]

Rank by relevance (0-100). Return JSON:
{{"results": [{{"id": "...", "score": 90, "reason": "..."}}]}}"""
        
        return prompt
    
    def _parse_response(self, text: str, senses: tuple) -> Optional[List[Dict]]:
        """è§£æå“åº”"""
        try:
            text = text.strip()
            text = text.replace('```json', '').replace('```', '').strip()
            
            data = json.loads(text)
            results = data.get('results', data.get('rankings', []))
            
            if not results:
                return None
            
            output = []
            for r in results:
                sense_id = r.get('id', r.get('sense_id', ''))
                
                definition = ""
                for sense in senses:
                    if sense.sense_id == sense_id:
                        definition = sense.definition
                        break
                
                output.append({
                    'sense_id': sense_id,
                    'definition': definition or r.get('definition', ''),
                    'confidence': float(r.get('score', r.get('confidence', 0))),
                    'reasoning': r.get('reason', r.get('reasoning', ''))
                })
            
            total = sum(r['confidence'] for r in output)
            if total > 0:
                for r in output:
                    r['confidence'] = (r['confidence'] / total) * 100
            
            return output
            
        except Exception:
            return None
    
    def _get_fallback_result(self, senses: tuple) -> List[Dict]:
        """é™çº§ç»“æœ"""
        n = len(senses)
        confidence = 100.0 / n if n > 0 else 0
        
        return [
            {
                'sense_id': sense.sense_id,
                'definition': sense.definition,
                'confidence': confidence,
                'reasoning': 'æ— æ³•è·å–AIåˆ†æ'
            }
            for sense in senses
        ]
    
    def find_common_words(self, sentence1: str, sentence2: str) -> List[str]:
        """æ‰¾å‡ºä¸¤ä¸ªå¥å­ä¸­çš„ç›¸åŒè¯æ±‡"""
        words1 = set(sentence1.lower().split())
        words2 = set(sentence2.lower().split())
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        import string
        words1 = {w.strip(string.punctuation) for w in words1}
        words2 = {w.strip(string.punctuation) for w in words2}
        
        # æ‰¾å‡ºäº¤é›†
        common = words1 & words2
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¯ï¼ˆå¯èƒ½æ˜¯åœç”¨è¯ï¼‰
        common = {w for w in common if len(w) > 2}
        
        return list(common)
    
    def analyze_word_in_contexts(
        self, 
        word: str, 
        context1: str, 
        context2: str
    ) -> Dict:
        """åˆ†æåŒä¸€ä¸ªè¯åœ¨ä¸¤ä¸ªä¸åŒä¸Šä¸‹æ–‡ä¸­çš„å«ä¹‰"""
        
        prompt = f"""Analyze the word "{word}" in two different contexts.

Context 1: {context1}
Context 2: {context2}

Task:
1. Determine if "{word}" has different meanings in these contexts
2. If different, explain each meaning
3. Rate confidence (0-100)

Return JSON:
{{
    "word": "{word}",
    "are_different": true/false,
    "context1_meaning": "meaning description",
    "context2_meaning": "meaning description", 
    "confidence": 85,
    "explanation": "why they are different or same"
}}"""
        
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            if not response or not response.candidates:
                return None
            
            if response.candidates[0].finish_reason != 1:
                return None
            
            text = response.text.strip()
            text = text.replace('```json', '').replace('```', '').strip()
            
            result = json.loads(text)
            return result
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return None


# ==================== Neo4jè¿æ¥ ====================

class Neo4jConnection:
    """è¿æ¥Neo4jè·å–è¯ä¹‰"""
    
    def __init__(self, uri="bolt://localhost:7687", user="neo4j", password="mlex2025"):
        try:
            from neo4j import GraphDatabase
            self.driver = GraphDatabase.driver(uri, auth=(user, password))
            self.connected = True
        except Exception as e:
            logger.warning(f"âš ï¸  Neo4jè¿æ¥å¤±è´¥: {e}")
            logger.warning("   å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            self.connected = False
    
    def get_word_senses(self, word: str) -> List[WordSense]:
        """ä»Neo4jè·å–è¯ä¹‰"""
        if not self.connected:
            return self._get_mock_senses(word)
        
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH (w:Word {entry: $word})-[:HAS_SENSE]->(s:Sense)
                    RETURN s.sense_id as sense_id,
                           s.definition as definition
                    ORDER BY s.sense_index
                    LIMIT 5
                """, word=word)
                
                senses = []
                for record in result:
                    senses.append(WordSense(
                        sense_id=record['sense_id'],
                        definition=record['definition']
                    ))
                
                return senses if senses else self._get_mock_senses(word)
        
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢å¤±è´¥: {e}")
            return self._get_mock_senses(word)
    
    def _get_mock_senses(self, word: str) -> List[WordSense]:
        """æ¨¡æ‹Ÿæ•°æ®ï¼ˆå½“Neo4jä¸å¯ç”¨æ—¶ï¼‰"""
        mock_data = {
            'makan': [
                WordSense('makan_1', 'to eat food'),
                WordSense('makan_2', 'to consume resources'),
                WordSense('makan_3', 'to corrode or erode'),
            ],
            'main': [
                WordSense('main_1', 'to play'),
                WordSense('main_2', 'to perform or act'),
                WordSense('main_3', 'to play musical instrument'),
            ],
            'buah': [
                WordSense('buah_1', 'fruit'),
                WordSense('buah_2', 'classifier for large objects'),
            ],
            'kena': [
                WordSense('kena_1', 'must or have to'),
                WordSense('kena_2', 'to be affected by'),
                WordSense('kena_3', 'to hit or strike'),
            ]
        }
        
        if word.lower() in mock_data:
            return mock_data[word.lower()]
        else:
            return [
                WordSense(f'{word}_1', f'meaning 1 of {word}'),
                WordSense(f'{word}_2', f'meaning 2 of {word}'),
            ]
    
    def close(self):
        if self.connected:
            self.driver.close()


# ==================== äº¤äº’å¼ç•Œé¢ ====================

class InteractiveWSD:
    """äº¤äº’å¼WSDå·¥å…·"""
    
    def __init__(self):
        self.wsd_service = None
        self.neo4j = None
    
    def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        print("\n" + "="*80)
        print("ğŸ”¤ MLEX - äº¤äº’å¼è¯ä¹‰æ¶ˆæ­§å·¥å…·")
        print("="*80)
        
        # åˆå§‹åŒ–Gemini
        try:
            self.wsd_service = GeminiWSDService()
            print("âœ… GeminiæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        except ValueError as e:
            print(f"\nâŒ {e}")
            return False
        
        # åˆå§‹åŒ–Neo4j
        self.neo4j = Neo4jConnection()
        if self.neo4j.connected:
            print("âœ… Neo4jè¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸  Neo4jæœªè¿æ¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        return True
    
    def show_menu(self):
        """æ˜¾ç¤ºèœå•"""
        print("\n" + "-"*80)
        print("é€‰æ‹©åŠŸèƒ½:")
        print("  1. å•è¯è¯ä¹‰æ¶ˆæ­§ (è¾“å…¥è¯ + å¥å­)")
        print("  2. å¥å­å¯¹æ¯”åˆ†æ (æ‰¾å‡ºç›¸åŒè¯çš„ä¸åŒå«ä¹‰)")
        print("  3. é€€å‡º")
        print("-"*80)
    
    def mode_single_word(self):
        """æ¨¡å¼1: å•è¯WSD"""
        print("\nğŸ“ æ¨¡å¼1: å•è¯è¯ä¹‰æ¶ˆæ­§")
        print("-"*80)
        
        word = input("\nè¯·è¾“å…¥è¦åˆ†æçš„è¯: ").strip()
        if not word:
            print("âŒ è¯ä¸èƒ½ä¸ºç©º")
            return
        
        context = input(f"è¯·è¾“å…¥åŒ…å« '{word}' çš„å¥å­: ").strip()
        if not context:
            print("âŒ å¥å­ä¸èƒ½ä¸ºç©º")
            return
        
        # æ£€æŸ¥è¯æ˜¯å¦åœ¨å¥å­ä¸­
        if word.lower() not in context.lower():
            print(f"âš ï¸  è­¦å‘Š: è¯ '{word}' ä¸åœ¨å¥å­ä¸­")
            confirm = input("ç»§ç»­åˆ†æ? (y/n): ").strip().lower()
            if confirm != 'y':
                return
        
        print(f"\nğŸ” æ­£åœ¨åˆ†æ...")
        
        # ä»Neo4jè·å–è¯ä¹‰
        senses = self.neo4j.get_word_senses(word)
        
        if not senses:
            print(f"âŒ æ‰¾ä¸åˆ°è¯ '{word}' çš„å®šä¹‰")
            return
        
        print(f"\nğŸ“š æ‰¾åˆ° {len(senses)} ä¸ªè¯ä¹‰:")
        for i, sense in enumerate(senses, 1):
            print(f"  {i}. {sense.definition}")
        
        # æ‰§è¡ŒWSD
        print(f"\nğŸ¤– AIåˆ†æä¸­...")
        results = self.wsd_service.disambiguate(word, context, tuple(senses))
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\n" + "="*80)
        print("ğŸ“Š åˆ†æç»“æœ:")
        print("="*80)
        print(f"å¥å­: {context}")
        print(f"è¯è¯­: {word}\n")
        
        for i, r in enumerate(results, 1):
            conf = r['confidence']
            
            # æ ¹æ®ç½®ä¿¡åº¦é€‰æ‹©å›¾æ ‡
            if conf > 70:
                icon = "ğŸŸ¢"
            elif conf > 40:
                icon = "ğŸŸ¡"
            else:
                icon = "ğŸ”´"
            
            print(f"{icon} æ’å {i}: {r['definition']}")
            print(f"   ç½®ä¿¡åº¦: {conf:.1f}%")
            print(f"   ç†ç”±: {r['reasoning']}\n")
    
    def mode_sentence_comparison(self):
        """æ¨¡å¼2: å¥å­å¯¹æ¯”"""
        print("\nğŸ“ æ¨¡å¼2: å¥å­å¯¹æ¯”åˆ†æ")
        print("-"*80)
        
        sentence1 = input("\nè¯·è¾“å…¥ç¬¬ä¸€ä¸ªå¥å­: ").strip()
        if not sentence1:
            print("âŒ å¥å­ä¸èƒ½ä¸ºç©º")
            return
        
        sentence2 = input("è¯·è¾“å…¥ç¬¬äºŒä¸ªå¥å­: ").strip()
        if not sentence2:
            print("âŒ å¥å­ä¸èƒ½ä¸ºç©º")
            return
        
        print(f"\nğŸ” å¯»æ‰¾ç›¸åŒçš„è¯...")
        
        # æ‰¾å‡ºç›¸åŒçš„è¯
        common_words = self.wsd_service.find_common_words(sentence1, sentence2)
        
        if not common_words:
            print("âŒ ä¸¤ä¸ªå¥å­æ²¡æœ‰ç›¸åŒçš„è¯")
            return
        
        print(f"\nğŸ“ æ‰¾åˆ° {len(common_words)} ä¸ªç›¸åŒçš„è¯: {', '.join(common_words)}")
        
        # åˆ†ææ¯ä¸ªç›¸åŒçš„è¯
        print(f"\nğŸ¤– åˆ†ææ¯ä¸ªè¯åœ¨ä¸¤ä¸ªå¥å­ä¸­çš„å«ä¹‰...")
        print("="*80)
        
        for word in common_words:
            print(f"\nğŸ”¤ è¯: {word}")
            print("-"*80)
            
            result = self.wsd_service.analyze_word_in_contexts(
                word, sentence1, sentence2
            )
            
            if not result:
                print("âŒ åˆ†æå¤±è´¥")
                continue
            
            print(f"å¥å­1: {sentence1}")
            print(f"å«ä¹‰: {result.get('context1_meaning', 'N/A')}\n")
            
            print(f"å¥å­2: {sentence2}")
            print(f"å«ä¹‰: {result.get('context2_meaning', 'N/A')}\n")
            
            are_different = result.get('are_different', False)
            confidence = result.get('confidence', 0)
            
            if are_different:
                print(f"âœ… å«ä¹‰ä¸åŒ (ç½®ä¿¡åº¦: {confidence}%)")
            else:
                print(f"âŒ å«ä¹‰ç›¸åŒ (ç½®ä¿¡åº¦: {confidence}%)")
            
            print(f"è¯´æ˜: {result.get('explanation', 'N/A')}")
            print("-"*80)
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        if not self.initialize():
            return
        
        while True:
            self.show_menu()
            
            choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
            
            if choice == '1':
                self.mode_single_word()
            
            elif choice == '2':
                self.mode_sentence_comparison()
            
            elif choice == '3':
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1, 2 æˆ– 3")
            
            input("\næŒ‰Enterç»§ç»­...")
        
        # æ¸…ç†
        if self.neo4j:
            self.neo4j.close()


# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»å‡½æ•°"""
    app = InteractiveWSD()
    
    try:
        app.run()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()